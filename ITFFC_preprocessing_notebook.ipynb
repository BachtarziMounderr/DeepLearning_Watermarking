{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193015b",
   "metadata": {},
   "source": [
    "\n",
    "# ITFFC — Preprocessing Notebook (Images → PNG + Cleaned Folders)\n",
    "\n",
    "This notebook performs **image preprocessing** on the dataset located at:\n",
    "\n",
    "```\n",
    "C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\n",
    "```\n",
    "\n",
    "### What it does\n",
    "- Scans all subfolders under `Dataset` (e.g., `logo`, `medical`, ...), and then each **class** subfolder (e.g., `Normal`, `Lung_Opacity`, `Viral Pneumonia`, `NonDemented`, `MildDemented`, etc.).  \n",
    "- For **each class folder**, creates a sibling folder named `<class>_processed` (e.g., `Normal_processed`).  \n",
    "- Loads images, applies minimal, safe preprocessing, and saves **PNG** versions with compression to reduce space.\n",
    "- Writes a **manifest CSV** with basic metadata (original path, processed path, width/height).  \n",
    "- Skips files that are not images and handles errors gracefully (logged to a CSV).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7306df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "\n",
    "# IMPORTANT: Use a raw string for Windows paths (prefix r)\n",
    "DATASET_ROOT = r\"C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\"\n",
    "\n",
    "# Preprocessing parameters\n",
    "long_side = 512         \n",
    "apply_clahe_medical = True  \n",
    "apply_clahe_logo = False    \n",
    "\n",
    "# File handling\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "force_rewrite = False        \n",
    "png_compress_level = 6       \n",
    "\n",
    "# Parallelism\n",
    "num_workers = 0             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2634b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 16:37:03) [MSC v.1929 64 bit (AMD64)]\n",
      "PIL version: 11.1.0\n",
      "cv2 available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cv2  # For CLAHE\n",
    "    _HAS_CV2 = True\n",
    "except Exception:\n",
    "    _HAS_CV2 = False\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PIL version:\", Image.__version__)\n",
    "print(\"cv2 available:\", _HAS_CV2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a4e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "\n",
    "def is_image_file(path: Path):\n",
    "    return path.suffix.lower() in valid_exts\n",
    "\n",
    "def ensure_rgb(img: Image.Image) -> Image.Image:\n",
    "    if img.mode in [\"RGB\", \"RGBA\"]:\n",
    "        return img.convert(\"RGB\")\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "def resize_keep_aspect(img: Image.Image, max_side: int) -> Image.Image:\n",
    "    if max_side is None or max_side <= 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    m = max(w, h)\n",
    "    if m <= max_side:\n",
    "        return img\n",
    "    scale = max_side / float(m)\n",
    "    new_w = max(1, int(round(w * scale)))\n",
    "    new_h = max(1, int(round(h * scale)))\n",
    "    return img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "def apply_clahe_rgb(img: Image.Image) -> Image.Image:\n",
    "    \n",
    "   \n",
    "    if not _HAS_CV2:\n",
    "        return img\n",
    "    arr = np.array(img.convert(\"RGB\"))\n",
    "    lab = cv2.cvtColor(arr, cv2.COLOR_RGB2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    L2 = clahe.apply(L)\n",
    "    lab2 = cv2.merge((L2, A, B))\n",
    "    rgb2 = cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)\n",
    "    return Image.fromarray(rgb2)\n",
    "\n",
    "def save_png(img: Image.Image, out_path: Path, compress_level: int = 6):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.save(out_path, format=\"PNG\", optimize=True, compress_level=int(compress_level))\n",
    "\n",
    "def decide_domain(path_in_dataset: Path) -> str:\n",
    " \n",
    "    parts = [p.lower() for p in path_in_dataset.parts]\n",
    "    if any(\"med\" in p for p in parts):  \n",
    "        return \"medical\"\n",
    "    if any(\"logo\" in p for p in parts):\n",
    "        return \"logo\"\n",
    "    return \"generic\"\n",
    "\n",
    "def processed_name(class_dir: Path) -> Path:\n",
    "    # Return sibling directory path with '_processed' suffix.\n",
    "    return class_dir.with_name(f\"{class_dir.name}_processed\")\n",
    "\n",
    "def gather_class_dirs(dataset_root: Path):\n",
    "    # Walks Dataset root and returns a list of leaf 'class' directories that contain images.\n",
    "    # E.g., .../Dataset/medical/covid19/Normal, etc.\n",
    "    class_dirs = []\n",
    "    for p in dataset_root.rglob(\"*\"):\n",
    "        if p.is_dir():\n",
    "            entries = list(p.iterdir())\n",
    "            has_images = any(is_image_file(x) for x in entries if x.is_file())\n",
    "            has_subdirs = any(x.is_dir() for x in entries)\n",
    "            if has_images and not has_subdirs:\n",
    "                class_dirs.append(p)\n",
    "    return sorted(class_dirs)\n",
    "\n",
    "def rel_to_root(path: Path, root: Path) -> Path:\n",
    "    try:\n",
    "        return path.relative_to(root)\n",
    "    except Exception:\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d6ef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 class folders (leaf dirs with images):\n",
      " - logo\\Logos\n",
      " - medcial\\alzheimer\\MildDemented\n",
      " - medcial\\alzheimer\\ModerateDemented\n",
      " - medcial\\alzheimer\\NonDemented\n",
      " - medcial\\alzheimer\\VeryMildDemented\n",
      " - medcial\\covid19\\Lung_Opacity\\images\n",
      " - medcial\\covid19\\Normal\\images\n",
      " - medcial\\covid19\\Viral Pneumonia\\images\n",
      "\\nProcessing logo\\Logos  ->  logo\\Logos_processed  (1435 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1435/1435 [00:50<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\alzheimer\\MildDemented  ->  medcial\\alzheimer\\MildDemented_processed  (896 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 896/896 [00:22<00:00, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\alzheimer\\ModerateDemented  ->  medcial\\alzheimer\\ModerateDemented_processed  (64 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 38.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\alzheimer\\NonDemented  ->  medcial\\alzheimer\\NonDemented_processed  (3200 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [01:24<00:00, 37.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\alzheimer\\VeryMildDemented  ->  medcial\\alzheimer\\VeryMildDemented_processed  (2240 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2240/2240 [00:58<00:00, 38.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\covid19\\Lung_Opacity\\images  ->  medcial\\covid19\\Lung_Opacity\\images_processed  (6012 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6012/6012 [11:06<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\covid19\\Normal\\images  ->  medcial\\covid19\\Normal\\images_processed  (10192 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10192/10192 [17:13<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nProcessing medcial\\covid19\\Viral Pneumonia\\images  ->  medcial\\covid19\\Viral Pneumonia\\images_processed  (1345 files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1345/1345 [02:07<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nDone.\n",
      "Manifest: C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\\preprocess_manifest.csv\n",
      "Errors  : C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\\preprocess_errors.csv (may be empty)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# Main processing\n",
    "# =========================\n",
    "\n",
    "root = Path(DATASET_ROOT)\n",
    "assert root.exists(), f\"DATASET_ROOT not found: {root}\"\n",
    "\n",
    "class_dirs = gather_class_dirs(root)\n",
    "print(f\"Found {len(class_dirs)} class folders (leaf dirs with images):\")\n",
    "for d in class_dirs:\n",
    "    print(\" -\", rel_to_root(d, root))\n",
    "\n",
    "manifest_rows = []\n",
    "error_rows = []\n",
    "\n",
    "def process_one(src_path: Path, dst_path: Path, domain: str):\n",
    "    # Load\n",
    "    img = Image.open(src_path)\n",
    "    img = ensure_rgb(img)\n",
    "    # Domain-specific steps\n",
    "    if long_side and long_side > 0:\n",
    "        img = resize_keep_aspect(img, long_side)\n",
    "    if domain == \"medical\" and apply_clahe_medical:\n",
    "        img = apply_clahe_rgb(img)\n",
    "    elif domain == \"logo\" and apply_clahe_logo:\n",
    "        img = apply_clahe_rgb(img)\n",
    "    # Save\n",
    "    save_png(img, dst_path, png_compress_level)\n",
    "    return img.size\n",
    "\n",
    "for class_dir in class_dirs:\n",
    "    out_dir = processed_name(class_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    domain = decide_domain(rel_to_root(class_dir, root))\n",
    "    files = [p for p in class_dir.iterdir() if p.is_file() and is_image_file(p)]\n",
    "    print(f\"\\\\nProcessing {rel_to_root(class_dir, root)}  ->  {rel_to_root(out_dir, root)}  ({len(files)} files)\")\n",
    "\n",
    "    for src in tqdm(files):\n",
    "        dst = out_dir / (src.stem + \".png\")\n",
    "        if dst.exists() and not force_rewrite:\n",
    "            # Collect existing metadata quickly (skip loading)\n",
    "            try:\n",
    "                with Image.open(dst) as _im:\n",
    "                    w, h = _im.size\n",
    "            except Exception:\n",
    "                w = h = -1\n",
    "            manifest_rows.append([str(src), str(dst), w, h, domain, \"skipped_exists\"])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            w, h = process_one(src, dst, domain)\n",
    "            manifest_rows.append([str(src), str(dst), w, h, domain, \"ok\"])\n",
    "        except Exception as e:\n",
    "            error_rows.append([str(src), str(dst), repr(e)])\n",
    "            print(\"Error on:\", src, \"->\", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Write manifests\n",
    "manif_path = root / \"preprocess_manifest.csv\"\n",
    "errs_path = root / \"preprocess_errors.csv\"\n",
    "with open(manif_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"src\", \"dst\", \"width\", \"height\", \"domain\", \"status\"])\n",
    "    writer.writerows(manifest_rows)\n",
    "\n",
    "with open(errs_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"src\", \"dst\", \"error\"])\n",
    "    writer.writerows(error_rows)\n",
    "\n",
    "print(\"\\\\nDone.\")\n",
    "print(\"Manifest:\", manif_path)\n",
    "print(\"Errors  :\", errs_path, \"(may be empty)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b6b2e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9688816-4069-4f14-876d-0e767fe2fc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
