{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193015b",
   "metadata": {},
   "source": [
    "\n",
    "# ITFFC — Preprocessing Notebook (Images → PNG + Cleaned Folders)\n",
    "\n",
    "This notebook performs **image preprocessing** on your dataset located at:\n",
    "\n",
    "```\n",
    "C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\n",
    "```\n",
    "\n",
    "### What it does\n",
    "- Scans all subfolders under `Dataset` (e.g., `logo`, `medical`, ...), and then each **class** subfolder (e.g., `Normal`, `Lung_Opacity`, `Viral Pneumonia`, `NonDemented`, `MildDemented`, etc.).  \n",
    "- For **each class folder**, creates a sibling folder named `<class>_processed` (e.g., `Normal_processed`).  \n",
    "- Loads images, applies minimal, safe preprocessing, and saves **PNG** versions with compression to reduce space.\n",
    "- Writes a **manifest CSV** with basic metadata (original path, processed path, width/height).  \n",
    "- Skips files that are not images and handles errors gracefully (logged to a CSV).\n",
    "\n",
    "> You can re-run cells safely; the code is **idempotent** (it won't reprocess already-existing PNGs unless `force_rewrite=True`).\n",
    "\n",
    "---\n",
    "\n",
    "### Default preprocessing\n",
    "- Ensure RGB format (or single-channel converted to RGB).\n",
    "- Optional resize (keep aspect ratio) so the **longest side = 512 px** (tweakable).\n",
    "- Optional **CLAHE** (contrast-limited adaptive histogram equalization) on luminance — helpful for X-ray-like medical images; can be toggled per \"domain\".\n",
    "- Save to PNG with compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "\n",
    "# IMPORTANT: Use a raw string for Windows paths (prefix r)\n",
    "DATASET_ROOT = r\"C:\\Users\\bacht\\Desktop\\Master2_S1\\ITFFC\\Dataset\"\n",
    "\n",
    "# Preprocessing parameters\n",
    "long_side = 512           # Max size for the longer side (set None to disable resizing)\n",
    "apply_clahe_medical = True  # Apply CLAHE for medical images\n",
    "apply_clahe_logo = False    # Usually not needed for logo images\n",
    "\n",
    "# File handling\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "force_rewrite = False        # If True, overwrite even if target exists\n",
    "png_compress_level = 6       # 0 (none) .. 9 (max)\n",
    "\n",
    "# Parallelism\n",
    "num_workers = 0              # 0 or 1 = no multiprocessing; set to >1 for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cv2  # For CLAHE\n",
    "    _HAS_CV2 = True\n",
    "except Exception:\n",
    "    _HAS_CV2 = False\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PIL version:\", Image.__version__)\n",
    "print(\"cv2 available:\", _HAS_CV2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "\n",
    "def is_image_file(path: Path):\n",
    "    return path.suffix.lower() in valid_exts\n",
    "\n",
    "def ensure_rgb(img: Image.Image) -> Image.Image:\n",
    "    if img.mode in [\"RGB\", \"RGBA\"]:\n",
    "        return img.convert(\"RGB\")\n",
    "    return img.convert(\"RGB\")\n",
    "\n",
    "def resize_keep_aspect(img: Image.Image, max_side: int) -> Image.Image:\n",
    "    if max_side is None or max_side <= 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    m = max(w, h)\n",
    "    if m <= max_side:\n",
    "        return img\n",
    "    scale = max_side / float(m)\n",
    "    new_w = max(1, int(round(w * scale)))\n",
    "    new_h = max(1, int(round(h * scale)))\n",
    "    return img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "def apply_clahe_rgb(img: Image.Image) -> Image.Image:\n",
    "    # Apply CLAHE on luminance (LAB space). Requires OpenCV.\n",
    "    # If cv2 is not available, returns the input unchanged.\n",
    "    if not _HAS_CV2:\n",
    "        return img\n",
    "    arr = np.array(img.convert(\"RGB\"))\n",
    "    lab = cv2.cvtColor(arr, cv2.COLOR_RGB2LAB)\n",
    "    L, A, B = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    L2 = clahe.apply(L)\n",
    "    lab2 = cv2.merge((L2, A, B))\n",
    "    rgb2 = cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)\n",
    "    return Image.fromarray(rgb2)\n",
    "\n",
    "def save_png(img: Image.Image, out_path: Path, compress_level: int = 6):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.save(out_path, format=\"PNG\", optimize=True, compress_level=int(compress_level))\n",
    "\n",
    "def decide_domain(path_in_dataset: Path) -> str:\n",
    "    # Returns 'medical' if 'medical' appears in path, 'logo' if 'logo' appears, else 'generic'.\n",
    "    parts = [p.lower() for p in path_in_dataset.parts]\n",
    "    if any(\"med\" in p for p in parts):  # tolerant of 'medcial' typo\n",
    "        return \"medical\"\n",
    "    if any(\"logo\" in p for p in parts):\n",
    "        return \"logo\"\n",
    "    return \"generic\"\n",
    "\n",
    "def processed_name(class_dir: Path) -> Path:\n",
    "    # Return sibling directory path with '_processed' suffix.\n",
    "    return class_dir.with_name(f\"{class_dir.name}_processed\")\n",
    "\n",
    "def gather_class_dirs(dataset_root: Path):\n",
    "    # Walks Dataset root and returns a list of leaf 'class' directories that contain images.\n",
    "    # E.g., .../Dataset/medical/covid19/Normal, etc.\n",
    "    class_dirs = []\n",
    "    for p in dataset_root.rglob(\"*\"):\n",
    "        if p.is_dir():\n",
    "            entries = list(p.iterdir())\n",
    "            has_images = any(is_image_file(x) for x in entries if x.is_file())\n",
    "            has_subdirs = any(x.is_dir() for x in entries)\n",
    "            if has_images and not has_subdirs:\n",
    "                class_dirs.append(p)\n",
    "    return sorted(class_dirs)\n",
    "\n",
    "def rel_to_root(path: Path, root: Path) -> Path:\n",
    "    try:\n",
    "        return path.relative_to(root)\n",
    "    except Exception:\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Main processing\n",
    "# =========================\n",
    "\n",
    "root = Path(DATASET_ROOT)\n",
    "assert root.exists(), f\"DATASET_ROOT not found: {root}\"\n",
    "\n",
    "class_dirs = gather_class_dirs(root)\n",
    "print(f\"Found {len(class_dirs)} class folders (leaf dirs with images):\")\n",
    "for d in class_dirs:\n",
    "    print(\" -\", rel_to_root(d, root))\n",
    "\n",
    "manifest_rows = []\n",
    "error_rows = []\n",
    "\n",
    "def process_one(src_path: Path, dst_path: Path, domain: str):\n",
    "    # Load\n",
    "    img = Image.open(src_path)\n",
    "    img = ensure_rgb(img)\n",
    "    # Domain-specific steps\n",
    "    if long_side and long_side > 0:\n",
    "        img = resize_keep_aspect(img, long_side)\n",
    "    if domain == \"medical\" and apply_clahe_medical:\n",
    "        img = apply_clahe_rgb(img)\n",
    "    elif domain == \"logo\" and apply_clahe_logo:\n",
    "        img = apply_clahe_rgb(img)\n",
    "    # Save\n",
    "    save_png(img, dst_path, png_compress_level)\n",
    "    return img.size\n",
    "\n",
    "for class_dir in class_dirs:\n",
    "    out_dir = processed_name(class_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    domain = decide_domain(rel_to_root(class_dir, root))\n",
    "    files = [p for p in class_dir.iterdir() if p.is_file() and is_image_file(p)]\n",
    "    print(f\"\\\\nProcessing {rel_to_root(class_dir, root)}  ->  {rel_to_root(out_dir, root)}  ({len(files)} files)\")\n",
    "\n",
    "    for src in tqdm(files):\n",
    "        dst = out_dir / (src.stem + \".png\")\n",
    "        if dst.exists() and not force_rewrite:\n",
    "            # Collect existing metadata quickly (skip loading)\n",
    "            try:\n",
    "                with Image.open(dst) as _im:\n",
    "                    w, h = _im.size\n",
    "            except Exception:\n",
    "                w = h = -1\n",
    "            manifest_rows.append([str(src), str(dst), w, h, domain, \"skipped_exists\"])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            w, h = process_one(src, dst, domain)\n",
    "            manifest_rows.append([str(src), str(dst), w, h, domain, \"ok\"])\n",
    "        except Exception as e:\n",
    "            error_rows.append([str(src), str(dst), repr(e)])\n",
    "            print(\"Error on:\", src, \"->\", e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Write manifests\n",
    "manif_path = root / \"preprocess_manifest.csv\"\n",
    "errs_path = root / \"preprocess_errors.csv\"\n",
    "with open(manif_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"src\", \"dst\", \"width\", \"height\", \"domain\", \"status\"])\n",
    "    writer.writerows(manifest_rows)\n",
    "\n",
    "with open(errs_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"src\", \"dst\", \"error\"])\n",
    "    writer.writerows(error_rows)\n",
    "\n",
    "print(\"\\\\nDone.\")\n",
    "print(\"Manifest:\", manif_path)\n",
    "print(\"Errors  :\", errs_path, \"(may be empty)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b6b2e",
   "metadata": {},
   "source": [
    "\n",
    "## Tips\n",
    "\n",
    "- If you see **file permission** errors on Windows, try running this notebook from a local Python environment with write access to your dataset folders.\n",
    "- To **disable resizing**, set `long_side = None` in the config cell and rerun.\n",
    "- To **reprocess** all images again, set `force_rewrite = True`.\n",
    "- The script infers the domain (\"medical\" vs. \"logo\") from directory names that contain `med` or `logo`. You can change that logic in `decide_domain`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
